<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>A tutorial on the cumulative calibration assessment and the cumulcalib package • cumulcalib</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="A tutorial on the cumulative calibration assessment and the cumulcalib package">
<meta property="og:description" content="cumulcalib">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">cumulcalib</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.0.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/tutorial.html">A tutorial on the cumulative calibration assessment and the cumulcalib package</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/resplab/cumulcalib/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>A tutorial on the cumulative calibration
assessment and the cumulcalib package</h1>
                        <h4 data-toc-skip class="author">Mohsen
Sadatsafavi</h4>
            
            <h4 data-toc-skip class="date">2024-06-05</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/resplab/cumulcalib/blob/HEAD/vignettes/tutorial.Rmd" class="external-link"><code>vignettes/tutorial.Rmd</code></a></small>
      <div class="hidden name"><code>tutorial.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p><em>cumulcalib</em> is an R package for the implementation of the
cumulative calibration assessment for risk prediction models.</p>
<p>If you use this approach for scientific work, please cite the
original paper: {Sadatsafavi M, Petkau J, Statistics In Medicine, 2004
(doi: 10.1002/sim.10138)}</p>
<p>In order to use <em>cumulcalib</em> efficiently you should be
reasonably familiar with the underlying statistical methodology. Please
visit the related publication above (or the arxiv version: <a href="https://arxiv.org/abs/2307.09713" class="external-link uri">https://arxiv.org/abs/2307.09713</a>).</p>
<p>We illustrate the use of this package, as well as basic
interpretations of the cumulative calibration plots, through a running
example.</p>
</div>
<div class="section level2">
<h2 id="setup-a-running-example-based-on-gusto-data">Setup: A running example based on GUSTO data<a class="anchor" aria-label="anchor" href="#setup-a-running-example-based-on-gusto-data"></a>
</h2>
<p>We use data from the GUSTO-I study which is widely used in predictive
analytics. These data are available from the <em>predtools</em>
package,</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/resplab/predtools" class="external-link">predtools</a></span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">gusto</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p>The outcome is 30-day mortality (we denote it by <span class="math inline">\(y\)</span>). We also convert the Killip score, a
measure of the severity of heart failure, to a binary variable (cut off
&gt;1):</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="va">gusto</span><span class="op">$</span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">gusto</span><span class="op">$</span><span class="va">day30</span></span>
<span>  <span class="va">gusto</span><span class="op">$</span><span class="va">kill</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">gusto</span><span class="op">$</span><span class="va">Killip</span><span class="op">)</span><span class="op">&gt;</span><span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="fl">1</span></span></code></pre></div>
<p>We will develope and validate a risk prediction model for 30-day
mortality after a heart attack based on these data. To create a
semi-realistic scenario, we use the non-US sub-sample of the data for
model development and the US sub-sample for model validation, and fit a
logistic regression model on the development sample.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="va">dev_data</span> <span class="op">&lt;-</span> <span class="va">gusto</span><span class="op">[</span><span class="op">!</span><span class="va">gusto</span><span class="op">$</span><span class="va">regl</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">7</span>, <span class="fl">9</span>, <span class="fl">10</span>, <span class="fl">11</span>, <span class="fl">12</span>, <span class="fl">14</span>, <span class="fl">15</span><span class="op">)</span>,<span class="op">]</span> <span class="co">#The regl variable contains location codes</span></span>
<span>  <span class="va">val_data</span> <span class="op">&lt;-</span> <span class="va">gusto</span><span class="op">[</span><span class="va">gusto</span><span class="op">$</span><span class="va">regl</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">7</span>, <span class="fl">9</span>, <span class="fl">10</span>, <span class="fl">11</span>, <span class="fl">12</span>, <span class="fl">14</span>, <span class="fl">15</span><span class="op">)</span>,<span class="op">]</span></span>
<span>  <span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="va">miloc</span> <span class="op">+</span> <span class="va">pmi</span> <span class="op">+</span> <span class="va">kill</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">pmin</a></span><span class="op">(</span><span class="va">sysbp</span>,<span class="fl">100</span><span class="op">)</span> <span class="op">+</span> <span class="va">pulse</span>, data<span class="op">=</span><span class="va">dev_data</span>, family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">binomial</a></span><span class="op">(</span>link<span class="op">=</span><span class="st">"logit"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The prevalence of the outcome in the development and validation
samples are, respectively, 0.07 and 0.07. Here are the coefficients of
the model:</p>
<table class="table">
<thead><tr class="header">
<th align="left"></th>
<th align="right">Coefficients</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">-2.0841861</td>
</tr>
<tr class="even">
<td align="left">age</td>
<td align="right">0.0781423</td>
</tr>
<tr class="odd">
<td align="left">milocOther</td>
<td align="right">0.4026548</td>
</tr>
<tr class="even">
<td align="left">milocAnterior</td>
<td align="right">0.5773049</td>
</tr>
<tr class="odd">
<td align="left">pmiyes</td>
<td align="right">0.4677806</td>
</tr>
<tr class="even">
<td align="left">kill</td>
<td align="right">0.7665919</td>
</tr>
<tr class="odd">
<td align="left">pmin(sysbp, 100)</td>
<td align="right">-0.0774778</td>
</tr>
<tr class="even">
<td align="left">pulse</td>
<td align="right">0.0182409</td>
</tr>
</tbody>
</table>
<p>We use this model to predict the outcome in the validation
sample:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="va">val_data</span><span class="op">$</span><span class="va">pi</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">model</span>, type<span class="op">=</span><span class="st">"response"</span>, newdata<span class="op">=</span><span class="va">val_data</span><span class="op">)</span></span></code></pre></div>
<p>Let’s start with the conventional calibration plot for this model,
which is an estimate of the average value of the true risk at a given
level of predicted risk (using the <em>calibration_plot</em> function of
the <em>predtools</em> package):</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="fu">predtools</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/predtools/man/calibration_plot.html" class="external-link">calibration_plot</a></span><span class="op">(</span><span class="va">val_data</span>, obs<span class="op">=</span><span class="st">"y"</span>, pred<span class="op">=</span><span class="st">"pi"</span><span class="op">)</span></span>
<span><span class="co">#&gt; $calibration_plot</span></span></code></pre></div>
<p><img src="tutorial_files/figure-html/unnamed-chunk-7-1.png" width="384">
The model seems to be well calibrated. One issue with such a plot is
that it generally requires binning (as done above) or smoothing. This is
because predicted risks often have many levels, and within each level of
predicted risk only a few, and mostly only one, <span class="math inline">\(y\)</span> is observed. This requirement makes
this assessment somewhat subjective: whether to use binning or
smoothing. If the former, how many bins? If the latter, which smoothing
method, and with which tuning parameter(s)?</p>
</div>
<div class="section level2">
<h2 id="objective-assessment-of-calibration-on-the-cumulative-domain">Objective assessment of calibration on the cumulative domain<a class="anchor" aria-label="anchor" href="#objective-assessment-of-calibration-on-the-cumulative-domain"></a>
</h2>
<p>The cumulative calibration assessment is based on the behavior of
standardized partial sum of <strong>prediction errors</strong> (i.e.,
<span class="math inline">\(y-\pi\)</span>, after ordering the data
ascendingly on <span class="math inline">\(\pi\)</span>). The promise is
that if the model is calibrated, the resulting partial sum, after
suitable standardization, will converge to the Brownian motion in the
[0,1] interval. This approach does not require any regularization.</p>
<p>Details of such standardization is provided in the original
publication. In brief, for the convergence to Brownian motion to work,
the ‘time’ jump at step i should be proportional to the variance of
<span class="math inline">\(y_i\)</span>, which, under the hypothesis
that the model is calibrated, is <span class="math inline">\(\pi_i(1-\pi_i)\)</span>.</p>
<div class="section level3">
<h3 id="using-cumulcalib-package-for-calibration-assessment">Using <em>cumulcalib</em> package for calibration assessment<a class="anchor" aria-label="anchor" href="#using-cumulcalib-package-for-calibration-assessment"></a>
</h3>
<p>To assess cumulative calibration using this approach via the
<em>cumulcalib</em> package, we use a simple function call and store the
results:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/resplab/cumulcalib" class="external-link">cumulcalib</a></span><span class="op">)</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cumulcalib.html">cumulcalib</a></span><span class="op">(</span><span class="va">val_data</span><span class="op">$</span><span class="va">y</span>, <span class="va">val_data</span><span class="op">$</span><span class="va">pi</span><span class="op">)</span> </span></code></pre></div>
<p>Let’s explore what type of results this call returns:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span>
<span><span class="co">#&gt; C_n (mean calibration error): -0.0015627663862339</span></span>
<span><span class="co">#&gt; C* (maximum absolute cumulative calibration error): 0.00200906446334084</span></span>
<span><span class="co">#&gt; Method: Two-part Brownian Bridge (BB)</span></span>
<span><span class="co">#&gt; S_n (Z score for mean calibration error) -1.00908104947661</span></span>
<span><span class="co">#&gt; B* (test statistic for maximum absolute bridged calibration error): 1.02844827843833</span></span>
<span><span class="co">#&gt; Component-wise p-values: mean calibration=0.312935765573665 | Distance (bridged)=0.240744428186207</span></span>
<span><span class="co">#&gt; Combined p-value (Fisher's method): 0.270143602791056</span></span>
<span><span class="co">#&gt; Location of maximum drift: 22402  | time value: 0.888235817046905  | predictor value: 0.333472525720663</span></span></code></pre></div>
<p>The following elements are returned:</p>
<ul>
<li><p><span class="math inline">\(C_n\)</span>: sample estimate of mean
calibration error (<span class="math inline">\(E(y-\pi)\)</span>)</p></li>
<li><p><span class="math inline">\(C^*\)</span> maximum absolute
cumulative prediction error, divided by the number of observations.
<span class="math inline">\(C^*\)</span> is a ‘distance’ metric, similar
to metrics such as Emax or the Integrated Calibration Index.</p></li>
</ul>
<p>The other components in the summary depend on the <em>Method</em>
requested for inference on model calibration. The default method is the
Brownian Bridge test, which returns the following:</p>
<ul>
<li><p><span class="math inline">\(S_n\)</span>: the Z score for mean
calibration error, obtained as <span class="math inline">\(\frac{nC_n}{\sqrt{\sum_1^n
\pi_i(1-\pi_i)}}\)</span>. Note that the denominator is the square-root
of total variance if the model is calibrated.</p></li>
<li><p><span class="math inline">\(B^*\)</span>: this is the maximum
distance of the random walk from the line that connects its start and
end (the bridge line, hence the ‘bridge’ test). Under the null
hypothesis that the model is calibrated, <span class="math inline">\(B^*\)</span> follows the Kolmogorov
distribution.</p></li>
<li><p>Component-wise p-values: These are individual p-values for each
component of the test. The first one is the Z-test for mean calibration
(testing if the average predicted and observed risks are equal). The
second one is the test of the deviation of the random walk from the line
that connects its origin and end (bridged distance).</p></li>
<li><p>Combined p-value: This is the unified p-value for moderate
calibration (based on Fisher’s method)</p></li>
<li><p>Location of maximum drift: This provides information about the
location that the maximum drift of the random walk occurs (corresponding
to <span class="math inline">\(C^*\)</span>). The rank of the
observation, time, and predictor values at this point are
reported.</p></li>
</ul>
<p>Note: the Brownian bridge test operates by combining two statistic:
<span class="math inline">\(C_n\)</span>, and maximum absolute deviation
of the random walk from the line that connects its origin and end
points. The test statistic related to the former is , and <span class="math inline">\(B^*\)</span> for the latter, which has a
Kolmogorov distribution under the null hypothesis. Because it can be
shown that these two statistics are independent, one combined p-value
can be generated using the Fisher’s method.</p>
<p>Based on the above results, both mean calibration p-value, and the
bridged random walk p-value show that the data are compatible with the
model being calibrated in this sample. Indeed, the combined p-value of
0.2701436 also indicated lack of strong evidence against the model being
calibrated for the US population.</p>
</div>
<div class="section level3">
<h3 id="graphical-assessment-of-calibration-using-cumulcalib-package">Graphical assessment of calibration using <em>cumulcalib</em>
package<a class="anchor" aria-label="anchor" href="#graphical-assessment-of-calibration-using-cumulcalib-package"></a>
</h3>
<p>The returning object from the function call can be directly
plotted:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span></code></pre></div>
<p><img src="tutorial_files/figure-html/unnamed-chunk-10-1.png" width="480"></p>
<p>The X axis is the ‘time’ value (running from 0 to 1). The
corresponding predicted values are shown on the second X-axis on top.
The default Y axis is the standardized sum (cumulative sum divided by
the square root of the sum of variance of predicted risks). The second Y
axis provides ‘scaled’ cumulative sum (divided by the number of
observations). This means the terminal value of the random walk can be
marked on the second Y-axis axis to identify mean calibration error.</p>
<p>The blue and red vertical lines, respectively, show the terminal
value of the random walk and its maximum bridged deviation (given the
default method, Brownian bridge, is used). The dotted lines of the same
color mark the critical value of the test (by default at 5% significance
level, see the documentation for the cumulcalib() function on how to
disable inference lines or change significance level).</p>
<p>Here it is obvious that neither the terminal value (mean calibration
error) nor the maximum deviation reach statistical significance.</p>
</div>
</div>
<div class="section level2">
<h2 id="how-do-different-forms-of-miscalibrations-look-on-the-cumulative-calibration-plot">How do different forms of miscalibrations look on the cumulative
calibration plot?<a class="anchor" aria-label="anchor" href="#how-do-different-forms-of-miscalibrations-look-on-the-cumulative-calibration-plot"></a>
</h2>
<p>The above results present how a calibrated model will look like.
Let’s test how different forms of miscalibration present themselves on
the cumulative calibration graph.</p>
<div class="section level3">
<h3 id="a-model-that-underestimates-the-risk">A model that underestimates the risk<a class="anchor" aria-label="anchor" href="#a-model-that-underestimates-the-risk"></a>
</h3>
<p>Let’s start with a model that under-estimates the risk. We mimic this
by applying an odds-ratio of 0.75 to predicted risks.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="va">val_data</span><span class="op">$</span><span class="va">pi2</span> <span class="op">&lt;-</span> <span class="va">val_data</span><span class="op">$</span><span class="va">pi</span><span class="op">*</span><span class="fl">0.75</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">val_data</span><span class="op">$</span><span class="va">pi</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="fl">0.75</span><span class="op">)</span><span class="op">)</span> <span class="co">#One-shot transformation of risk to odds and back</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cumulcalib.html">cumulcalib</a></span><span class="op">(</span><span class="va">val_data</span><span class="op">$</span><span class="va">y</span>, <span class="va">val_data</span><span class="op">$</span><span class="va">pi2</span><span class="op">)</span> </span>
<span>  <span class="fu">predtools</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/predtools/man/calibration_plot.html" class="external-link">calibration_plot</a></span><span class="op">(</span><span class="va">val_data</span>, obs<span class="op">=</span><span class="st">"y"</span>, pred<span class="op">=</span><span class="st">"pi2"</span><span class="op">)</span></span>
<span><span class="co">#&gt; $calibration_plot</span></span></code></pre></div>
<p><img src="tutorial_files/figure-html/unnamed-chunk-11-1.png" width="480"></p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span></code></pre></div>
<p><img src="tutorial_files/figure-html/unnamed-chunk-11-2.png" width="480"></p>
<p>As can be seen above, when predicted risks are systematically smaller
than actual risks, prediction errors are generally positive, resulting
in a generally ascending curve. Clearly, the Z-test component of the
bridge test is rejected at 0.05 level (the corresponding p-value is
4.6582653^{-20}). However, as can bee see by the red markings on the
graph, the bridge component is not affected by such systematic error
(the corresponding p-value is 0.2022575). As the overall p-value for
moderate calibration is affected by both, it remains significant
(p-value: 0). As such, the null hypothesis that the model is moderately
calibrated is rejected at 0.05 significance level.</p>
</div>
<div class="section level3">
<h3 id="a-model-that-overestimates-the-risk">A model that overestimates the risk<a class="anchor" aria-label="anchor" href="#a-model-that-overestimates-the-risk"></a>
</h3>
<p>We mimic this by applying an odds-ratio of 1.25 to predicted
risks.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="va">val_data</span><span class="op">$</span><span class="va">pi2</span> <span class="op">&lt;-</span> <span class="va">val_data</span><span class="op">$</span><span class="va">pi</span><span class="op">*</span><span class="fl">1.25</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">val_data</span><span class="op">$</span><span class="va">pi</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="fl">1.25</span><span class="op">)</span><span class="op">)</span> <span class="co">#One-shot transformation of risk to odds and back</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cumulcalib.html">cumulcalib</a></span><span class="op">(</span><span class="va">val_data</span><span class="op">$</span><span class="va">y</span>, <span class="va">val_data</span><span class="op">$</span><span class="va">pi2</span><span class="op">)</span> </span>
<span>  <span class="fu">predtools</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/predtools/man/calibration_plot.html" class="external-link">calibration_plot</a></span><span class="op">(</span><span class="va">val_data</span>, obs<span class="op">=</span><span class="st">"y"</span>, pred<span class="op">=</span><span class="st">"pi2"</span><span class="op">)</span></span>
<span><span class="co">#&gt; $calibration_plot</span></span></code></pre></div>
<p><img src="tutorial_files/figure-html/unnamed-chunk-12-1.png" width="480"></p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span></code></pre></div>
<p><img src="tutorial_files/figure-html/unnamed-chunk-12-2.png" width="480"></p>
<p>Here, the opposite happens: when predicted risks are systematically
larger than actual risks, prediction errors are generally negative,
resulting in a generally descending curve. Again, the Z-test component
of the bridge test is rejected at 0.05 level (the corresponding p-value
is 5.1912618^{-19}), but the bridge component is not affected by such
systematic error (the corresponding p-value is 0.4221737). Again, as the
overall p-value for moderate calibration is affected by both, it remains
significant (p-value: 0). As such, the null hypothesis that the model is
moderately calibrated is rejected at 0.05 significance level.</p>
</div>
<div class="section level3">
<h3 id="over-fittedd-model">Over-fittedd model<a class="anchor" aria-label="anchor" href="#over-fittedd-model"></a>
</h3>
<p>To demonstrate how an over-fitted model might look, we refit the
model based on only a sub-sample of 500 rows from the development
sample. The intuition is that because of the small development sample,
the model might not be calibrated. In particular, it might be
over-fitted.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="va">dev_data2</span> <span class="op">&lt;-</span> <span class="va">dev_data</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">dev_data</span><span class="op">)</span>, <span class="fl">500</span>, replace<span class="op">=</span><span class="cn">F</span><span class="op">)</span>,<span class="op">]</span></span>
<span>  <span class="va">model2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="va">miloc</span> <span class="op">+</span> <span class="va">pmi</span> <span class="op">+</span> <span class="va">kill</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">pmin</a></span><span class="op">(</span><span class="va">sysbp</span>,<span class="fl">100</span><span class="op">)</span> <span class="op">+</span> <span class="va">pulse</span>, data<span class="op">=</span><span class="va">dev_data2</span>, family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">binomial</a></span><span class="op">(</span>link<span class="op">=</span><span class="st">"logit"</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">val_data</span><span class="op">$</span><span class="va">pi2</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">model2</span>, type<span class="op">=</span><span class="st">"response"</span>, newdata<span class="op">=</span><span class="va">val_data</span><span class="op">)</span></span></code></pre></div>
<p>Let’s look at the calibration plot</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="fu">predtools</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/predtools/man/calibration_plot.html" class="external-link">calibration_plot</a></span><span class="op">(</span><span class="va">val_data</span>, obs<span class="op">=</span><span class="st">"y"</span>, pred<span class="op">=</span><span class="st">"pi2"</span><span class="op">)</span></span>
<span><span class="co">#&gt; $calibration_plot</span></span></code></pre></div>
<p><img src="tutorial_files/figure-html/unnamed-chunk-14-1.png" width="480"></p>
<p>The model is indeed not as well calibrated as the model based on the
full development sample. Let’s repeat the cumulative calibration
exercise</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="va">res2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cumulcalib.html">cumulcalib</a></span><span class="op">(</span><span class="va">val_data</span><span class="op">$</span><span class="va">y</span>, <span class="va">val_data</span><span class="op">$</span><span class="va">pi2</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">res2</span><span class="op">)</span></span>
<span><span class="co">#&gt; C_n (mean calibration error): 0.000155141189373162</span></span>
<span><span class="co">#&gt; C* (maximum absolute cumulative calibration error): 0.00834106759839258</span></span>
<span><span class="co">#&gt; Method: Two-part Brownian Bridge (BB)</span></span>
<span><span class="co">#&gt; S_n (Z score for mean calibration error) 0.106201501405249</span></span>
<span><span class="co">#&gt; B* (test statistic for maximum absolute bridged calibration error): 5.66522040991455</span></span>
<span><span class="co">#&gt; Component-wise p-values: mean calibration=0.915422479736154 | Distance (bridged)=0</span></span>
<span><span class="co">#&gt; Combined p-value (Fisher's method): 0</span></span>
<span><span class="co">#&gt; Location of maximum drift: 18992  | time value: 0.420294629063075  | predictor value: 0.106004714711078</span></span></code></pre></div>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">res2</span><span class="op">)</span></span></code></pre></div>
<p><img src="tutorial_files/figure-html/unnamed-chunk-15-1.png" width="480"></p>
<p>Here, despite the fact that average predicted risks are close to the
average actual risks (notice the terminal position of the random walk),
miscalibration is quite obvious: the model seems to be making
under-estimated risks at low values (the increasing trend of cumulative
prediction error), followed by overestimating the risk later (the
declining curve). This inverse U shape is a typical signature of an
over-fitted model.</p>
<p>If we repeat the similar steps for inference, we will obtain the
following p-values: 0.9154225 for mean miscalibration, 0 for the bridge
component, and 0 for the unified test. Unlike models that systematically
under-predict or over-predict the risk, here it is the bridge component
of the test that catches the miscalibration.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Mohsen Sadatsafavi.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
